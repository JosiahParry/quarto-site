{
  "hash": "fe776e431508ca19e2081759746e6b5a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Valve: putting R in production\"\ndate: 2023-08-22\ncategories: [rust, r, production]\nfreeze: true\n---\n\n\nThis blog post is based on my most recent YouTube video. Please give it a watch! \n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/11FM-dxxi3M\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n\n\n::: {.cell}\n\n:::\n\n\nI've been grinding on a new tool for a few months now. And I'm hyped to formally introduce you to it. It's called [Valve](https://valve.josiahparry.com) And Valve is going to make R in production kick a\\$\\$.ðŸ”¥\n\nWe've all seen those click bait articles saying \"Don't Put R in production\" or telling you that R can't make machine learning models for production. Those \"hot takes\" are uninformed and can be applied to other languages such as Python. That's a bunch of malarkey.\n\n[![](images/paste-1.png){width=50% fig-align=\"center\"}](https://towardsdatascience.com/dont-use-r-in-production-e2f4c9dd4a7b)\n\nLet's get right down to it. Let's talk \"production.\" And let me be clear: R belongs in production. But we as the R community need to learn how to do that and be better advocates.\n\nWhen I say \"production\" I'm talking about making your code work with any other system. And that's where RESTful APIs come in. If I've lost you at \"RESTful\", [watch my previous video here](https://www.youtube.com/watch?v=w4yHEQWct20&list=UULFX78SUhrloA6Cn3aW_e8C_A&index=22). \n\n::: {.column-margin}\n[![](images/paste-15.png){width=75% fig-align=\"center\"}](https://www.youtube.com/watch?v=w4yHEQWct20&list=UULFX78SUhrloA6Cn3aW_e8C_A&index=22)\n:::\n\nREST relies on HTTP, which is the foundation of the internet and is a common tongue. It's like if Esperanto actually worked. REST APIs provide a language-agnostic way to expose functionality over the web.\n\n[Plumber](https://www.rplumber.io/) is an R package that converts your R functions into a RESTful API meaning any tool that can communicate in HTTP can call your R functions. It converts R code like this into an http endpoint.\n\nAt it's core Valve is a web server that runs multiple {plumber} APIs in parallel. Valve spins up and down plumber APIs as needed.\n\n![](images/paste-21.png){width=75% fig-align=\"center\"}\n\nIt's designed to work with any existing plumber API. And because of that it supports {vetiver} out of the box.\n\n::: {.column-margin}\n![](images/paste-22.png){width=50%}\n:::\n\nVetiver is a framework built by Julia Silge and Isabel Zimmerman from Posit that simplifies putting machine learning models built with tidymodels into a production setting. And since, the goal is R in production, Valve can be easily integrated into Docker containers and deployed with DigitalOcean, AWS, Azure, or whatever other orchestration tools you have available.\n\nValve is akin to Gunicorn for Flask apps and FastAPI.\n\n::: {layout=\"[[1,1], [1]]\"}\n![](images/gunicor.png)\n\n![](images/flask.png)\n\n![](images/fastapi.png)\n:::\n\nTo understand why Valve is so powerful, we need to first understand how plumber works and its limitations. Plumber works by writing a function definition and providing annotations using a special comment character `#*`. Let's take a look at a very simple example.\n\nThe three main components of a plumber API are:\n\n-   the function definition\n-   the request type `@post`\n-   endpoint `/add-2`\n\nIn a nutshell plumber works by spawning a single web server using the {httpuv} R package. The webserver captures incoming http requests, captures the provided parameters, body, and requested endpoint. Based on the endpoint, it passes the parameters to the function. The result is then \"serialized\" into the correct output type. By default, this is `json`.\n\n![](images/plumber-nutshell.png)\n\nFor example, we might be calling the `/add-2` endpoint. The process looks a bit like this. We have a GET request. The endpoint is colored red. Then the parameters are colored blue. The request is captured by the web-server. The endpoints are checked. Then the parameters are passed to the function and the user gets the result.\n\n![](images/request.png)\n\nYou can see how this is powerful! But there is one major thing holding this back. This is all running in a single R process. R, like Python, is single threaded. That means each request that comes in has to be added to a queue. The next request cannot be processed until the previous one has been.\n\nValve helps by running multiple plumber APIs concurrently. Valve is built specifically for plumber, in Rust, and by leveraging the power Tokio framework. Instead of having a single plumber API and a single R process handling all requests, there is another web server handling all incoming requests. This web server is build using Tokio.\n\n\n:::{layout-ncol=3}\n\n![](images/plumber.png){width=33%}\n\n![](images/rustacean-flat-happy.png){width=33%}\n\n![](images/tokio.png){width=33%}\n\n:::\n\nThe app has a number of pre-specified worker threads. Each worker is capable of taking an incoming request, processing it, and returning a response. These worker threads will delegate the request to another plumber API. These plumber APIs are sitting in a connection pool waiting to be accessed. The APIs will spawn and de-spawn according to the amount of incoming traffic.\n\n![](images/valve.png)\n\nWhat this means is that instead of being able to handle 1 request at a time, we can handle as many requests as there are workers concurrently. This allows us to take advantage of more than a single R process at a time and, as a result, we can utilize more of the compute resources available to us.\n\nSo how do you install Valve? There are two ways in which you can install Valve. The first is to use the Rust package manager Cargo. This is my personal recommendation. If you don't have Rust and cargo installed, don't worry it is the second easiest language I've ever installed.\n\n![](images/paste-12.png)\n\nFollow this one liner and it'll handle the installation for you.\n\nTo install Valve with cargo run\n\n``` shell\ncargo install valve-rs --no-default-features\n```\n\nDoing this will install the Valve binary and make it available to you as a command line tool. Alternatively, if you want to install valve as an R package you can do so via the R-universe. The R-universe version has pre-built binaries for Windows, Mac, and Ubuntu which means you do not need to have rust installed. But again, its easy, so give it a shot!\n\n``` r\ninstall.packages(\n    \"valve\", \n    repos = c(\"https://josiahparry.r-universe.dev\", \"https://cloud.r-project.org\")\n)\n```\n\nTo follow along with the rest of these demos you can check out code in the [github repository](https://github.com/JosiahParry/youtube-tutorials/tree/main/intro-valve).\n\nHere I want to demo just how easy it is to use Valve and what the experience is like. For this simple example we will run a plumber API with one endpoint `/zzz` which will sleep for a specified amount of time. We'll create a Valve app with 10 workers and plumber APIs.\n\n```shell\nvalve -n 10 -w 10\n```\n\nYou'll notice that only one API is spawned at the start. This is because connections are spawned based on incoming demand. As we send more requests, the plumber APIs will spawn. If, after a specified amount of time, they go stale, they will de-spawn. However, you do have the ability to control the minimum number of plumber APIs.\n\n```shell\nValve starting at: 127.0.0.1:3000\nSpawning plumber API at 127.0.0.1:11094\n```\n\nWe're going to create a simple function `sleep()` which will call the zzz endpoint at a specified port for a specified amount of time. We'll use `furrr` to create 10 sessions and call the function 10 times on valve app.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep <- function(port, secs) {\n  httr2::request(\n        paste0(\"127.0.0.1:\", port, \"/sleep?zzz=\", secs)\n    ) |> \n    httr2::req_perform() |> \n    httr2::resp_body_string()\n}\n```\n:::\n\n\nNow with the function defined we can use furrr to run the function in parallel\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(furrr)\nplan(multisession, workers = 10)\n```\n:::\n\n\nWe will call the function 10 times using `future_map()` . The first time this runs we can see that more plumber APIs are being spawned. This takes somewhere between 3 and 4 seconds the first time we run it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart <- Sys.time()\nfurrr::future_map(1:10, ~ sleep(3000, 2))\nmulti_total <- Sys.time() - start\nmulti_total \n#> Time difference of 3.653488 secs\n```\n:::\n\n\nIf you watch your terminal, you will see additional plumber connections being spawned. \n\n```shell\nValve starting at: 127.0.0.1:3000\nSpawning plumber API at 127.0.0.1:11094\nSpawning plumber API at 127.0.0.1:35714\nSpawning plumber API at 127.0.0.1:15674\nSpawning plumber API at 127.0.0.1:30746\nSpawning plumber API at 127.0.0.1:26860\nSpawning plumber API at 127.0.0.1:54939\nSpawning plumber API at 127.0.0.1:5592\nSpawning plumber API at 127.0.0.1:46549\nSpawning plumber API at 127.0.0.1:53346\nSpawning plumber API at 127.0.0.1:44956\n```\n\nIf we run this again, we get something much closer to two seconds total for sending all 10 requests.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart <- Sys.time()\nfurrr::future_map(1:10, ~ sleep(3000, 2))\nmulti_total <- Sys.time() - start\nmulti_total \n#> Time difference of 2.013385 secs\n```\n:::\n\n\nNow, we can do the same thing with all 10 workers calling just one of the spawned plumber APIs.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart <- Sys.time()\nfurrr::future_map(1:10, ~ sleep(24817, 2))\n(total <- Sys.time() - start)\n#> Time difference of 20.04956 secs\n```\n:::\n\n\nThat's a huge different. That is a lot more performance that we are squeezing out of this plumber API by creating multiple to run concurrently.\n\nIn an R session load {valve}.\n\n```r\nlibrary(valve)\n```\n\nNext, we will use the function `valve_run()` to run our plumber API. This function has a lot of handy defaults to moderately scale your plumber API. By default it looks for the file `plumber.R` in your working directory.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvalve_run(\"plumber.R\", n_max = 10)\n#> Valve app hosted at <http://127.0.0.1:3000>\n#> Spawning plumber API at 127.0.0.1:49015\n```\n:::\n\n\nThe CLI works just like the R function with two differences. We call it from the command line and the syntax is a smidgen different.\n\nFrom the command line we can run `valve â€“help` to see the arguments that we can provide. The CLI has the same defaults as the R package.\n\n```shell\nvalve --help\nUsage: valve [-h <host>] [-p <port>] [-n <n-max>] [-w <workers>] [-f <file>] [--check-unused <check-unused>] [--max-age <max-age>] [--n-min <n-min>]\n\nDistribute your plumber API in parallel.\n\nOptions:\n  -h, --host        host to serve APIs on\n  -p, --port        the port to serve the main application on\n  -n, --n-max       the maximum number of plumber APIs to spawn\n  -w, --workers     number of Tokio workers to spawn to handle requests\n  -f, --file        path to the plumber API (default `plumber.R`)\n  --check-unused    default 10. Interval in seconds when to check for unused\n                    connections\n  --max-age         default 5 mins. How long an API can go unused before being\n                    killed in seconds.\n  --n-min           the maximum number of plumber APIs to spawn\n  --help            display usage information\n```\n\nNow I want to illustrate scaling a machine learning model with {vetiver} and valve. They do so by wrapping the model into a plumber API. I've created a sample plumber API based on [Julia's recent Tidy Tuesday screencast in which she creates an XGBoost model](https://juliasilge.com/blog/childcare-costs/).\n\n![](images/paste-14.png)\n\nI've taken this example and used vetiver to create a plumber API to serve predictions from this model. One could deploy this API as is with Docker or something like Posit Connect. If going down the Docker approach, we can make this a bit more performant by using Valve.\n\n:::{.callout-note}\nThe scripts to generate the vetiver model and API are in the [Github repo](https://github.com/JosiahParry/youtube-tutorials/tree/main/intro-valve).\n:::\n\nTo make this into a Valve app all we need to do is pass provide the plumber API file to valve and we're on our way! I've written some simple bench marks using drill to compare the performance of the two approaches. With valve we will use 5 concurrent processes and test it.\n\n```shell\nvalve -f vetiver-api.R -n 5 -w 5\n```",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}