---
title: "Univariate Spatial Dimensionality Reduction"
subtitle: "Extening PCoA and Moran Eigenvector Maps to include attributes"
date: "2024-05-22"
categories: [spatial, r]
freeze: true
---

In discussing principal coordinate analysis (PCoA), the question naturally arose of "how could we incorporate non-spatial data into this method?" Well, that is what I wanted to explore.

If we include an attribute e.g. crime rate, and embed that into the spatial components generated by PCoA we would truly be doing spatial dimension reduction. Not only would we be encoding spatial patterns, but we would be encoding spatial patterns as they relate to some attribute across the spatial surface. 

This is already explored in the context of gene expression via [`{spatialPCA}`](https://github.com/shangll123/SpatialPCA) ([website here](https://lulushang.org/SpatialPCA_Tutorial/)). This is somewhat different to what I explored in my previous blog post. My brief review of the paper and R package tells me that the spatialPCA method applies the spatial weights matrix into the covariance matrix used in PCA. 

What I'm going to explore is a bit different than that. 

# Univariate spatial encoding

Naturally, we want to look at how we can incorporate attributes into PCoA. Lets first start by creating a spatial weights matrix. 

```{r include = FALSE}
#| code-fold: true
#|
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(irlba)
library(sfdep)
library(spdep)
library(ggplot2)
library(spatialreg)
```

As always, we use the Guerry dataset since it is tried and true. Here I create a spatial weights matrix using contiguity to identify neighborhoods and we use a guassian kernel (like spatial PCA). The Gaussian kernel makes it so that locations that are closer have more weight than those further away. Since we are using contiguity, the distance is estimated by using centroids.

```{r}
geom <- guerry$geometry
pnts <- st_centroid(geom)

# neighbors via contiguity
nb <- st_contiguity(geom)

# gaussian kernel weights for neighbors
wt <- st_kernel_weights(nb, pnts, "gaussian")

(listw <- nb2listw(nb, wt, style = "B"))
```

## Revisiting the spatial lag

The spatial lag is arguably the most fundamental spatial statistic. It is, in essence, the weighted average of a variable $x$ across a neighborhood.

To calculate the spatial lag, referred often to as $Wy$, we multiply our spatial weights matrix by our neighboring values. Let's walk through how this works really quickly. 

We have the index positions of our neighbors and the weights that are associated with each of them. 
```{r}
#| layout-ncol: 2
head(nb)
head(wt)
```

To calculate the spatial lag we first find the neighbors' values for a vector x, multiply them by the weights and sum them up. In this case the variable is literacy.

```{r}
x <- guerry$literacy
xj <- find_xj(x, nb)
head(xj)
```

With the neighboring values, we can multiply them by the spatial weights. 

```{r}
xj_wt <- purrr::map2(xj, wt, \(.xj, .wt) .xj * .wt)
head(xj_wt)
```

The last step in calculating the spatial lag is to sum that all up: 

```{r}
x_lag <- vapply(xj_wt, sum, numeric(1))
head(x_lag)
```
Or, simplified, that is: 

```{r}
head(st_lag(x, nb, wt))
```

## Stopping short of the spatial lag

We use the spatial lag to get a univariate estimate of the spatial neighborhoods value. We have a matrix of xj values that we multiply the spatial weights matrix and then perform a row summation.

What if we _didn't_ perform that summation, and instead applied PCA onto the weighted values of `xj`? 

We would then be encoding space and attributes into the components! In the below code chunk I am converting the spatial weights matrix to a sparse matrix and also creating a sparse matrix of the neighboring values. I am also scaling them. 

```{r}
m <- as(listw, "CsparseMatrix")

xj <- as(
  nb2listw(
    nb, find_xj(scale(x), nb), style = "B"
  ),
  "CsparseMatrix"
)
```

Now, we multiply them and perform PCA on the resultant matrix: 

```{r}
#| code-fold: true
plot_comp <- function(comp) {
    ggplot(guerry, aes(fill = comp)) +
    geom_sf(color = "black", lwd = 0.2) +
    scale_fill_viridis_c() +
    theme_void() +
    theme(legend.position = "none")
}
```
```{r}
#| layout-ncol: 2
comps <- prcomp_irlba(xj * m, 4)

plot_comp(comps$rotation[,1])
plot_comp(comps$rotation[,2])
plot_comp(comps$rotation[,3])
plot_comp(comps$rotation[,4])
```

We can see that there are some meaningful components in here! 

The original variable's distribution: 

```{r}
ggplot(guerry, aes(fill = literacy)) +
    geom_sf(color = "black", lwd = 0.2) +
    scale_fill_viridis_c() +
    labs(title = "Literacy") +
    theme_void()
```

We can see that there is some resemblance to original variable in these components. 

## Do they exhibit spatial autocorrelation?

Yes, yes they do! 

```{r}
#| code-fold: true
comps_autocorr <- function(comps) {
    apply(comps$rotation, 2, function(.x) {
        broom::tidy(global_moran_test(.x, nb, wt))
        }, simplify = FALSE) |>
        dplyr::bind_rows(.id = "component") |>
        dplyr::mutate(
            estimate1 = round(estimate1, 3), p.value = rstatix::p_format(p.value)
        ) |>
        dplyr::select(component, "Moran's I" = estimate1, p_val = p.value) 
}
```

```{r}
comps_autocorr(comps)
```


How do we use this, though? That is the part I am not so clear on. We have multiple components and they all exhibit _significant_ autocorrelation. The applicability of each of these components may depend a lot upon what they are used to predict. The interpretation of them is tougher than identifying the applicability. 

```{r}
#| code-fold: true
regress_component <- function(z) {
  vars <- setdiff(
    colnames(guerry), 
    c("code_dept", "count", "region", "geometry", "area", "distance", "ave_id_geo", "main_city", "dept", "department")
  )
  
  lapply(vars, \(var) {
    broom::glance(summary(lm(guerry[[var]] ~ z)))
  }) |> 
    setNames(vars) |> 
    dplyr::bind_rows(.id = "variable") |> 
    dplyr::arrange(-r.squared) |> 
    dplyr::select(variable, r.squared) |>
    dplyr::filter(r.squared > 0.1)
}
```

If we regress our components upon the variables in the Guerry dataset we might be able to see which patterns they can help explain away. This helper function filters out regressions with an $R^2$ of less than 0.1.

```{r}
#| layout-ncol: 2
regress_component(comps$rotation[,1])
regress_component(comps$rotation[,2])
regress_component(comps$rotation[,3])
regress_component(comps$rotation[,4])
```

Interestingly the 3rd and 4th components are the most useful if we were looking for something to predict uponâ€”this is a derived use case where we're fishing for something that looks good. 

## Univariate Spatial Attribute Comopnent w/ Regression

Let's explore this 4rd component a bit more. If we regress `prostitutes ~ literacy` we see that there is a much weaker model. Surprisingly, in fact. And the residuals are only very mildly autocorrelated. Why is the component such a strong predictor????

```{r}
mod <- lm(prostitutes ~ literacy, data = guerry)
summary(mod)
global_moran_test(resid(mod), nb, wt)
```

Adding in the component to the model, the $R^2$ shoots right up! But why?

```{r}
mod <- lm(prostitutes ~ literacy + comps$rotation[,4], data = guerry)
summary(mod)
global_moran_test(resid(mod), nb, wt)
```

Often when there is a spatial effect of a variable, we utilize its spatial lag in the model. This is an SLX model but simplified.

```{r}
mod <- lm(prostitutes ~ literacy + st_lag(x, nb, wt), data = guerry)
summary(mod)
global_moran_test(resid(mod), nb, wt)
```

Is this all autocorrelation? What if we look at including just a spatial component? What is interesting is that if we recreate this process using _only_ the Moran's Eigenvectors, there is nothing meaningful to be extracted that predicts prostitution as well as the spatial univariate component! 

```{r}
#| code-fold: true
#| layout-ncol: 4
sp_comps <- irlba::prcomp_irlba(
  scale(scale(m, T, T), T, F), 4
)

comps_autocorr(sp_comps)
regress_component(sp_comps$rotation[,1])
regress_component(sp_comps$rotation[,2])
regress_component(sp_comps$rotation[,3])
regress_component(sp_comps$rotation[,4])

```




